{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utilities.fits import fit\n",
    "# from utilities import plot\n",
    "import tensorflow_probability.substrates.jax as tfp\n",
    "dist = tfp.distributions\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from gpytorch.constraints import GreaterThan\n",
    "from skgpytorch.metrics import mean_squared_error, negative_log_predictive_density\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# from datasets.dataset_load import dataset_loader\n",
    "from utilities import plot,fits,gmm,errors,predict,preprocess\n",
    "\n",
    "# device = \"cpu\"\n",
    "# torch.set_default_dtype(torch.float32)\n",
    "# torch.set_default_tensor_type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel, PeriodicKernel, MaternKernel, CosineKernel\n",
    "from skgpytorch.models import SVGPRegressor, SGPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train ={ 2: {\n",
    "          'start_time': \"2011-04-21\" ,\n",
    "          'end_time': \"2011-05-21\"\n",
    "    }\n",
    "   ,\n",
    "     3: {\n",
    "          'start_time': \"2011-04-19\" ,\n",
    "          'end_time': \"2011-05-22\"\n",
    "    }\n",
    "}\n",
    "test = {  1: {\n",
    "          'start_time': \"2011-04-28\" ,\n",
    "          'end_time': \"2011-05-15\"\n",
    "        } \n",
    "   \n",
    "      \n",
    "}\n",
    "appliances = [\"Dish Washer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def dataset_load(appliances, train, test=None):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_train_timestamp = []\n",
    "    n = 9\n",
    "    units_to_pad = n // 2\n",
    "    scaler_x = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    scaler_time = StandardScaler()\n",
    "    # train\n",
    "    for key, values in train.items():\n",
    "        df = pd.read_csv(\n",
    "            f\"datasets/Building{key}_NILM_data_basic.csv\", usecols=[\"Timestamp\", \"main\", appliances[0]])\n",
    "        df[\"date\"] = pd.to_datetime(df[\"Timestamp\"]).dt.date\n",
    "        startDate = datetime.strptime(values[\"start_time\"], \"%Y-%m-%d\").date()\n",
    "        endDate = datetime.strptime(values[\"end_time\"], \"%Y-%m-%d\").date()\n",
    "\n",
    "        if startDate > endDate:\n",
    "            raise \"Start Date must be smaller than Enddate.\"\n",
    "\n",
    "        df = df[(df[\"date\"] >= startDate) & (df[\"date\"] <= endDate)]\n",
    "        df.dropna(inplace=True)\n",
    "        x = df[\"main\"].values\n",
    "        y = df[appliances[0]].values\n",
    "        timestamp_train = (pd.to_datetime(df[\"Timestamp\"]).astype(int)/ 10**18).values\n",
    "        x = jnp.pad(x, (units_to_pad, units_to_pad),\n",
    "                    'constant', constant_values=(0, 0))\n",
    "        x = jnp.array([x[i: i + n] for i in range(len(x) - n + 1)])\n",
    "        x_train.extend(x)\n",
    "        y_train.extend(y)\n",
    "        x_train_timestamp.extend(torch.Tensor(timestamp_train))\n",
    "\n",
    "\n",
    "    x_train = jnp.array(x_train)\n",
    "    y_train = jnp.array(y_train).reshape(-1, 1)\n",
    "    x_train_timestamp = torch.Tensor(x_train_timestamp).reshape(-1,1)\n",
    "    x_train = scaler_x.fit_transform(x_train)\n",
    "    y_train = scaler_y.fit_transform(y_train)\n",
    "    x_train_timestamp = scaler_time.fit_transform(x_train_timestamp)\n",
    "\n",
    "\n",
    "    # test\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    x_test_timestamp = []\n",
    "    for key, values in test.items():\n",
    "        df = pd.read_csv(\n",
    "            f\"datasets/Building{key}_NILM_data_basic.csv\", usecols=[\"Timestamp\", \"main\", appliances[0]])\n",
    "        df[\"date\"] = pd.to_datetime(df[\"Timestamp\"]).dt.date\n",
    "        startDate = datetime.strptime(values[\"start_time\"], \"%Y-%m-%d\").date()\n",
    "        endDate = datetime.strptime(values[\"end_time\"], \"%Y-%m-%d\").date()\n",
    "\n",
    "        if startDate > endDate:\n",
    "            raise \"Start Date must be smaller than Enddate.\"\n",
    "\n",
    "        df = df[(df[\"date\"] >= startDate) & (df[\"date\"] <= endDate)]\n",
    "        df.dropna(inplace=True)\n",
    "        x = df[\"main\"].values\n",
    "        y = df[appliances[0]].values\n",
    "        timestamp = (pd.to_datetime(df[\"Timestamp\"]).astype(int)/ 10**18).values\n",
    "        x = jnp.pad(x, (units_to_pad, units_to_pad),\n",
    "                    'constant', constant_values=(0, 0))\n",
    "        x = jnp.array([x[i: i + n] for i in range(len(x) - n + 1)])\n",
    "        x_test.extend(x)\n",
    "        y_test.extend(y)\n",
    "        x_test_timestamp.extend(timestamp)\n",
    "\n",
    "    x_test = jnp.array(x_test)\n",
    "    y_test = jnp.array(y_test).reshape(-1, 1)\n",
    "    x_test_timestamp = torch.Tensor(x_test_timestamp).reshape(-1,1)\n",
    "\n",
    "    x_test = scaler_x.transform(x_test)\n",
    "    x_test_timestamp = scaler_time.transform(x_test_timestamp)\n",
    "#     y_test = scaler_y.transform(y_test)\n",
    "\n",
    "    x_train = jnp.array(x_train).reshape(x_train.shape[0], n)\n",
    "    y_train = jnp.array(y_train)\n",
    "    x_train_timestamp = torch.Tensor(x_train_timestamp).reshape(x_train_timestamp.shape[0], 1)\n",
    "    x_test = jnp.array(x_test).reshape(x_test.shape[0], n)\n",
    "    y_test = jnp.array(y_test)\n",
    "    x_test_timestamp = torch.Tensor(x_test_timestamp).reshape(x_test_timestamp.shape[0], 1)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, x_train_timestamp, x_test_timestamp, scaler_x, scaler_y, scaler_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, x_train_timstamp, x_test_timestamp, scaler_x, scaler_y,scaler_time= dataset_load(appliances, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes =15000\n",
    "n = 9\n",
    "# x_train_full = jnp.concatenate((jnp.array(x_train.reshape(-1,n)), jnp.array(np.array(x_train_timstamp))), axis=1)\n",
    "# x_test_full = jnp.concatenate((jnp.array(x_test.reshape(-1,n)), jnp.array(np.array(x_test_timestamp))), axis=1)\n",
    "# x_train_full.shape, x_test_full.shape\n",
    "\n",
    "x = torch.Tensor(np.array(x_train))\n",
    "y = torch.Tensor(np.array(y_train)).reshape(-1)\n",
    "xt = torch.Tensor(np.array(x_test))\n",
    "yt = torch.Tensor(np.array(y_test)).reshape(-1)\n",
    "\n",
    "# if x.shape[0]>indexes:\n",
    "#   x1 = x[:indexes]\n",
    "#   y1 = y[:indexes]\n",
    "\n",
    "# xt1= x[indexes:]\n",
    "# yt1 = y[indexes:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30436, 9]), torch.Size([10138, 9]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7a903a5990>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = x.size(-1)\n",
    "class LargeFeatureExtractor1(torch.nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(LargeFeatureExtractor1, self).__init__()\n",
    "        self.add_module('lstm', torch.nn.LSTM(data_dim, 256,4))\n",
    "        # self.add_module('linear1', torch.nn.Linear(data_dim, 250))\n",
    "        # self.add_module('relu1', torch.nn.ReLU())\n",
    "        # self.add_module('linear2', torch.nn.Linear(250, 50))     \n",
    "        # self.add_module('relu2', torch.nn.ReLU())                  \n",
    "        # self.add_module('linear3', torch.nn.Linear(50, 9))       \n",
    "        # self.add_module('relu3', torch.nn.ReLU())   \n",
    "        # self.add_module('linear4', torch.nn.Linear(250, 100))       \n",
    "        # self.add_module('relu4', torch.nn.ReLU())                         \n",
    "        # self.add_module('linear5', torch.nn.Linear(100, 9))\n",
    "\n",
    "class LargeFeatureExtractor2(torch.nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(LargeFeatureExtractor2, self).__init__()\n",
    "        # self.add_module('lstm', torch.nn.LSTM(data_dim, 500,2))\n",
    "        # self.add_module('linear1', torch.nn.Linear(data_dim, 1000))\n",
    "        # self.add_module('relu1', torch.nn.ReLU())\n",
    "        # self.add_module('linear2', torch.nn.Linear(1000, 500))     \n",
    "        # self.add_module('relu2', torch.nn.ReLU())                  \n",
    "        self.add_module('linear1', torch.nn.Linear(256, 64))       \n",
    "        self.add_module('relu1', torch.nn.ReLU())   \n",
    "        self.add_module('linear2', torch.nn.Linear(64, 9))                          \n",
    "        # self.add_module('linear1', torch.nn.Linear(200, 99))  \n",
    "\n",
    "feature_extractor1 = LargeFeatureExtractor1().cuda()\n",
    "feature_extractor2 = LargeFeatureExtractor2().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "        def __init__(self, train_x, train_y, likelihood):\n",
    "            super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "            self.mean_module = gpytorch.means.ConstantMean()\n",
    "            self.base_covar_module =  gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=9)) \n",
    "            #+ gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=1, active_dims=(49)))*gpytorch.kernels.ScaleKernel(gpytorch.kernels.PeriodicKernel(ard_num_dims=1, active_dims=(49)))\n",
    "            # self.covar_module = gpytorch.kernels.GridInterpolationKernel(\n",
    "            #     gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=2)),\n",
    "            #     num_dims=2, grid_size=100\n",
    "            # )\n",
    "            self.covar_module = InducingPointKernel(self.base_covar_module, inducing_points=train_x[np.arange(0, train_x.shape[0], 25)], likelihood=likelihood)\n",
    "            print(self.covar_module)\n",
    "            self.feature_extractor1 = feature_extractor1\n",
    "            self.feature_extractor2 = feature_extractor2\n",
    "\n",
    "            # This module will scale the NN features so that they're nice values\n",
    "            # self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # We're first putting our data through a deep net (feature extractor)\n",
    "            projected_x, (hn,cn) = self.feature_extractor1(x)\n",
    "            print(projected_x.shape, hn.shape,cn.shape)\n",
    "            projected_x = self.feature_extractor2(projected_x)\n",
    "            # print(projected_x.shape, hn.shape,cn.shape)\n",
    "            # projected_x = self.scale_to_bounds(projected_x)  # Make the NN values \"nice\"\n",
    "            projected_x = projected_x - projected_x.min(0)[0]\n",
    "            projected_x = 2 * (projected_x / projected_x.max(0)[0]) - 1\n",
    "            # print(projected_x.dtype)\n",
    "            mean_x = self.mean_module(projected_x) #projected_\n",
    "            covar_x = self.covar_module(projected_x)\n",
    "            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InducingPointKernel(\n",
      "  (base_kernel): ScaleKernel(\n",
      "    (base_kernel): RBFKernel(\n",
      "      (raw_lengthscale_constraint): Positive()\n",
      "    )\n",
      "    (raw_outputscale_constraint): Positive()\n",
      "  )\n",
      "  (likelihood): GaussianLikelihood(\n",
      "    (noise_covar): HomoskedasticNoise(\n",
      "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = GPRegressionModel(x, y, likelihood)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    likelihood = likelihood.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f6be5144ed4788baaea9a4e378f1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/desai.aadesh/miniconda3/envs/nlim/lib/python3.10/site-packages/gpytorch/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/home/desai.aadesh/miniconda3/envs/nlim/lib/python3.10/site-packages/gpytorch/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(\n",
      "/home/desai.aadesh/miniconda3/envs/nlim/lib/python3.10/site-packages/gpytorch/kernels/inducing_point_kernel.py:61: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  /opt/conda/conda-bld/pytorch_1656352645774/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2183.)\n",
      "  inv_root = torch.triangular_solve(eye, chol)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/desai.aadesh/miniconda3/envs/nlim/lib/python3.10/site-packages/gpytorch/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-04 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m/home/desai.aadesh/NLIM/new_files/deepkernel_dish2.ipynb Cell 13\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/desai.aadesh/NLIM/new_files/deepkernel_dish2.ipynb#ch0000012vscode-remote?line=21'>22</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mmll(output, y\u001b[39m.\u001b[39mcuda())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/desai.aadesh/NLIM/new_files/deepkernel_dish2.ipynb#ch0000012vscode-remote?line=22'>23</a>\u001b[0m \u001b[39m# loss_arr.append(loss.cpu())\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/desai.aadesh/NLIM/new_files/deepkernel_dish2.ipynb#ch0000012vscode-remote?line=23'>24</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/desai.aadesh/NLIM/new_files/deepkernel_dish2.ipynb#ch0000012vscode-remote?line=24'>25</a>\u001b[0m iterator\u001b[39m.\u001b[39mset_postfix(loss\u001b[39m=\u001b[39mloss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/desai.aadesh/NLIM/new_files/deepkernel_dish2.ipynb#ch0000012vscode-remote?line=25'>26</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/nlim/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlim/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "training_iterations = 300\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "loss_arr =[]\n",
    "def train():\n",
    "    iterator = tqdm.notebook.tqdm(range(training_iterations))\n",
    "    for i in iterator:\n",
    "        # Zero backprop gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Get output from model\n",
    "        output = model(x.cuda())\n",
    "        # Calc loss and backprop derivatives\n",
    "        loss = -mll(output, y.cuda())\n",
    "        # loss_arr.append(loss.cpu())\n",
    "        loss.backward()\n",
    "        iterator.set_postfix(loss=loss.item())\n",
    "        optimizer.step()\n",
    "\n",
    "%time train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30436, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([40574, 256]) torch.Size([4, 256]) torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "with torch.no_grad(), gpytorch.settings.use_toeplitz(False), gpytorch.settings.fast_pred_var():\n",
    "    preds = model(xt.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 24.752034248907492\n"
     ]
    }
   ],
   "source": [
    "print('Test MAE: {}'.format(torch.mean(torch.abs(torch.tensor(scaler_y.inverse_transform(preds.mean.cpu().reshape(-1,1)).squeeze()) - yt))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test MAE: 26.224479548161128 build3\n",
    "#Test MAE: 9.841791420581126 build2\n",
    "#Test MAE: 24.752034248907492 build1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a19952a8cb0d513e360355f3718fc7b5b0ccef7313ddd97e7b7ab66b1ecfbb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
